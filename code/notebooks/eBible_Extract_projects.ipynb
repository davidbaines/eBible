{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidbaines/eBible/blob/main/eBible_Extract_projects.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8dvXZnMNniY",
        "outputId": "5b7ed291-bec7-41e8-c3ba-ef03d68758b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define base folder"
      ],
      "metadata": {
        "id": "awnVICVNmGVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base = \"/content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible\""
      ],
      "metadata": {
        "id": "V-dpuImLmX4J"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6Az2jLOoHPa"
      },
      "source": [
        "# Import modules, define rewrite boolean, directory paths and logging file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JsAEZs5WoPbv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff20ad02-e9f9-4d9c-b77a-22207bf03169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/projects\n",
            "/content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/metadata\n",
            "/content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/metadata/translations.csv\n",
            "/content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/metadata/copyrights.csv\n",
            "/content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "/content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/MT/scripture\n",
            "/content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/logs\n",
            "rewrite = False\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from datetime import date, datetime\n",
        "from os import listdir, makedirs, environ\n",
        "from os.path import exists\n",
        "from glob import iglob\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import warnings\n",
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "import codecs\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "rewrite = False  # tells if the project is overwritten when it already exists\n",
        "\n",
        "corpus = Path(base)\n",
        "ebible_projects = corpus / 'projects'\n",
        "ebible_metadata = corpus / 'metadata'\n",
        "ebible_translations_csv = ebible_metadata / 'translations.csv'\n",
        "ebible_copyright_csv = ebible_metadata / 'copyrights.csv'\n",
        "ebible_redistributable = corpus / \"redistributable/projects\"\n",
        "ebible_extractions = corpus / \"MT/scripture\"\n",
        "ebible_logs = corpus / \"logs\"\n",
        "\n",
        "print(ebible_projects)\n",
        "print(ebible_metadata)\n",
        "print(ebible_translations_csv)\n",
        "print(ebible_copyright_csv)\n",
        "print(ebible_redistributable)\n",
        "print(ebible_extractions)\n",
        "print(ebible_logs)\n",
        "print(f\"rewrite = {rewrite}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install packages and clone the silnlp repo"
      ],
      "metadata": {
        "id": "wk_2lgrHjLGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "!pip install sil-machine\n",
        "!pip install boto3\n",
        "!pip install s3path\n",
        "!pip install requests\n",
        "\n",
        "!git clone https://github.com/sillsdev/silnlp"
      ],
      "metadata": {
        "id": "cpIB4aWzjUpL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d7382bd-8abd-42cc-f1bb-98b8a810f821"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-0.21.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sil-machine\n",
            "  Downloading sil_machine-0.7.4-py3-none-any.whl (205 kB)\n",
            "\u001b[K     |████████████████████████████████| 205 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from sil-machine) (1.21.6)\n",
            "Requirement already satisfied: sortedcontainers<3.0.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from sil-machine) (2.4.0)\n",
            "Collecting regex<2022.0.0,>=2021.7.6\n",
            "  Downloading regex-2021.11.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "\u001b[K     |████████████████████████████████| 749 kB 65.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx<3.0.0,>=2.6.3 in /usr/local/lib/python3.7/dist-packages (from sil-machine) (2.6.3)\n",
            "Requirement already satisfied: chardet>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from sil-machine) (3.0.4)\n",
            "Installing collected packages: regex, sil-machine\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2022.6.2\n",
            "    Uninstalling regex-2022.6.2:\n",
            "      Successfully uninstalled regex-2022.6.2\n",
            "Successfully installed regex-2021.11.10 sil-machine-0.7.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.25.2-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 8.5 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.7 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting botocore<1.29.0,>=1.28.2\n",
            "  Downloading botocore-1.28.2-py3-none-any.whl (9.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.3 MB 59.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.29.0,>=1.28.2->boto3) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 71.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.29.0,>=1.28.2->boto3) (1.15.0)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.12 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.25.2 botocore-1.28.2 jmespath-1.0.1 s3transfer-0.6.0 urllib3-1.26.12\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting s3path\n",
            "  Downloading s3path-0.3.4-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: boto3>=1.16.35 in /usr/local/lib/python3.7/dist-packages (from s3path) (1.25.2)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from s3path) (5.2.1)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3>=1.16.35->s3path) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3>=1.16.35->s3path) (0.6.0)\n",
            "Requirement already satisfied: botocore<1.29.0,>=1.28.2 in /usr/local/lib/python3.7/dist-packages (from boto3>=1.16.35->s3path) (1.28.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.29.0,>=1.28.2->boto3>=1.16.35->s3path) (1.26.12)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.29.0,>=1.28.2->boto3>=1.16.35->s3path) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.29.0,>=1.28.2->boto3>=1.16.35->s3path) (1.15.0)\n",
            "Installing collected packages: s3path\n",
            "Successfully installed s3path-0.3.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2022.9.24)\n",
            "Installing collected packages: urllib3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.12\n",
            "    Uninstalling urllib3-1.26.12:\n",
            "      Successfully uninstalled urllib3-1.26.12\n",
            "Successfully installed urllib3-1.25.11\n",
            "Cloning into 'silnlp'...\n",
            "remote: Enumerating objects: 4716, done.\u001b[K\n",
            "remote: Counting objects: 100% (650/650), done.\u001b[K\n",
            "remote: Compressing objects: 100% (200/200), done.\u001b[K\n",
            "remote: Total 4716 (delta 468), reused 603 (delta 448), pack-reused 4066\u001b[K\n",
            "Receiving objects: 100% (4716/4716), 11.68 MiB | 9.18 MiB/s, done.\n",
            "Resolving deltas: 100% (3346/3346), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMdkvOPbzdMg"
      },
      "source": [
        "# Define methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mHI0bcJYz6ID"
      },
      "outputs": [],
      "source": [
        "from pandas.core.groupby import groupby\n",
        "# Columns are easier to use if they are valid python identifiers:\n",
        "def improve_column_names(df): df.columns = df.columns.str.strip().str.lower().str.replace('\"', '').str.replace(\"'\", '')\\\n",
        "    .str.replace('(', '').str.replace(')', '').str.replace(' ', '_')\n",
        "\n",
        "\n",
        "def log_and_print(s, type='ínfo'):\n",
        "    log_file.write(f\"{type.upper()}: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} {s}\\n\")\n",
        "    print(s)\n",
        "\n",
        "\n",
        "def get_extracted_projects(dir_extracted):\n",
        "\n",
        "    extracted = []\n",
        "    for line in listdir(dir_extracted):\n",
        "        m = re.search(r\".+-(.+).txt$\", line)\n",
        "        if m:\n",
        "            extracted.append(m.group(1))\n",
        "    \n",
        "    return extracted\n",
        "\n",
        "\n",
        "def get_books_type(files):\n",
        "\n",
        "    for book in files:\n",
        "        m = re.search(r\".*GEN|JON.*\", book)\n",
        "        if m:\n",
        "            return \"OT+NT\"\n",
        "    return \"NT\"\n",
        "\n",
        "\n",
        "def get_conclusion(versification):\n",
        "\n",
        "    if versification != \"\":\n",
        "        return versification\n",
        "    else:\n",
        "        return \"4\" # English\n",
        "\n",
        "\n",
        "def conclude_versification_from_OT(dan_3, dan_5, dan_13):\n",
        "    if dan_3 == 30:\n",
        "        versification = \"4\"  # English\n",
        "    elif dan_3 == 33 and dan_5 == 30:\n",
        "        versification = \"1\"  # Original\n",
        "    elif dan_3 == 33 and dan_5 == 31:\n",
        "        versification = \"5\"  # Russian Protestant\n",
        "    elif dan_3 == 97:\n",
        "        versification = \"2\"  # Septuagint\n",
        "    elif dan_3 == 100:\n",
        "        if dan_13 == 65:\n",
        "            versification = \"3\"  # Vulgate\n",
        "        else:\n",
        "            versification = \"6\"  # Russian Orthodox\n",
        "    else:\n",
        "        versification = \"\"\n",
        "\n",
        "    return versification\n",
        "\n",
        "def conclude_versification_from_NT(jhn_6, act_19, rom_16):\n",
        "    if jhn_6 == 72:\n",
        "        versification = \"3\"  # Vulgate\n",
        "    elif act_19 == 41:\n",
        "        versification = \"4\"  # English\n",
        "    elif rom_16 == 24:\n",
        "        versification = \"6\"  # Russian Orthodox (same as Russian Protestant)\n",
        "    elif jhn_6 == 71 and act_19 == 40:\n",
        "        versification = \"1\"  # Original (Same as Septuagint)\n",
        "    else:\n",
        "        versification = \"\"\n",
        "\n",
        "    return versification\n",
        "\n",
        "\n",
        "def get_last_verse(project, book, chapter):\n",
        "\n",
        "    ch = str(chapter)\n",
        "\n",
        "    for book_file in iglob(f\"{project}/*{book}*\"):\n",
        "        last_verse = \"0\"\n",
        "        try:\n",
        "            f = codecs.open(book_file, \"r\", encoding=\"utf-8\", errors=\"ignore\")\n",
        "        except Exception as e:\n",
        "            print(f\"Could not open {book_file}, reason:  {e}\")\n",
        "            continue\n",
        "        try:\n",
        "            in_chapter = False\n",
        "            for line in f:\n",
        "                m = re.search(r\"\\\\c ? ?([0-9]+).*\", line)\n",
        "                if m:\n",
        "                    if m.group(1) == ch:\n",
        "                        in_chapter = True\n",
        "                    else:\n",
        "                        in_chapter = False\n",
        "\n",
        "                m = re.search(r\"\\\\v ? ?([0-9]+).*\", line)\n",
        "                if m:\n",
        "                    if in_chapter:\n",
        "                        last_verse = m.group(1)\n",
        "        except Exception as e:\n",
        "            print(f\"Something went wrong in reading {book_file}, reason:  {e}\")\n",
        "            return None\n",
        "        try:\n",
        "            return int(last_verse)\n",
        "        except Exception as e:\n",
        "            print(f\"Could not convert {last_verse} into an integer in {book_file}, reason:  {e}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "def get_checkpoints_OT(project):\n",
        "    dan_3 = get_last_verse(project, \"DAN\", 3)\n",
        "    dan_5 = get_last_verse(project, \"DAN\", 5)\n",
        "    dan_13 = get_last_verse(project, \"DAN\", 13)\n",
        "\n",
        "    return dan_3, dan_5, dan_13\n",
        "\n",
        "\n",
        "def get_checkpoints_NT(project):\n",
        "    jhn_6 = get_last_verse(project, \"JHN\", 6)\n",
        "    act_19 = get_last_verse(project, \"ACT\", 19)\n",
        "    rom_16 = get_last_verse(project, \"ROM\", 16)\n",
        "\n",
        "    return jhn_6, act_19, rom_16\n",
        "\n",
        "\n",
        "def get_versification(project):\n",
        "    versification = \"\"\n",
        "    books = get_books_type(listdir(project))\n",
        "\n",
        "    if books == \"OT+NT\":\n",
        "        dan_3, dan_5, dan_13 = get_checkpoints_OT(project)\n",
        "        versification = conclude_versification_from_OT(dan_3, dan_5, dan_13)\n",
        "\n",
        "    if not versification:\n",
        "        jhn_6, act_19, rom_16 = get_checkpoints_NT(project)\n",
        "        versification = conclude_versification_from_NT(jhn_6, act_19, rom_16)\n",
        "\n",
        "    return versification\n",
        "\n",
        "\n",
        "def add_settings_file(project, language_code):\n",
        "    versification = get_conclusion(get_versification(project))\n",
        "    setting_file_stub = f\"\"\"<ScriptureText>\n",
        "    <Versification>{versification}</Versification>\n",
        "    <LanguageIsoCode>{language_code}:::</LanguageIsoCode>\n",
        "    <Naming BookNameForm=\"41-MAT\" PostPart=\"{project.name}.usfm\" PrePart=\"\" />\n",
        "</ScriptureText>\"\"\"\n",
        "\n",
        "    settings_file = project / 'Settings.xml'\n",
        "    f = open(settings_file, \"w\")\n",
        "    f.write(setting_file_stub)\n",
        "    f.close()\n",
        "\n",
        "\n",
        "def copy_to_working_directory(project, language_code):\n",
        "    folder = ebible_redistributable / project.name\n",
        "    if exists(folder):\n",
        "      if rewrite:\n",
        "        shutil.rmtree(folder)\n",
        "      else:\n",
        "        return 0\n",
        "    log_and_print(f\"copying {project.name} to {ebible_redistributable}\")\n",
        "    shutil.copytree(project, folder)\n",
        "    add_settings_file(folder, language_code)\n",
        "    return 1\n",
        "\n",
        "\n",
        "def get_redistributable_projects():\n",
        "\n",
        "    ok_copyrights = [\"by-nc-nd\", \"by-nd\", \"by-sa\"]\n",
        "    redistributable = {}\n",
        "    translations_info = pd.read_csv(ebible_translations_csv)\n",
        "    copyright_info = pd.read_csv(ebible_copyright_csv)\n",
        "    improve_column_names(translations_info)\n",
        "    improve_column_names(copyright_info)\n",
        "    copyright_info.rename(columns={'id': 'translationid'}, inplace=True)\n",
        "    combined = pd.merge(translations_info, copyright_info, on='translationid', how='left')\n",
        "\n",
        "    for index, row in combined.iterrows():\n",
        "        if row[\"redistributable\"] and (row[\"licence_type\"] in ok_copyrights or row[\"copyright_holder\"] == \"Public Domain\"):\n",
        "            redistributable[row[\"translationid\"]] = row[\"languagecode\"]\n",
        "\n",
        "    return redistributable\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oQDn6UjoYw1"
      },
      "source": [
        "# Prepare redistributable projects to be extracted. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJxJjQnsvx_z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da732ae3-89da-407e-ede3-628bddacb8ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting converting eBible projects for extracting...\n",
            "copying ziw to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying aoj to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying sri to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying caoNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying priNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying sbe to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying ctuBl to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying paoNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying tdt to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying cac to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying srqNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying tbg to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying iou to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying kms to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying kyg to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying lifNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying zpcNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying bba to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying gofRNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying qufNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying mxbNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying guiNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying hot to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying gah to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying yuj to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying eseNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying aby to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying tue to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying zabNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying xtmNTpp to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying qveNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying susa to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying xtdNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying ssg to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying zadNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying pibNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying zsrNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying tav to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying cjoNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying kjs to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying bhl to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying kud to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying boaNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying dhgduwadha to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying kpg to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying santel to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying rai to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying zpuNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying taj to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying seyNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying cnlNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying usa to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying ubr to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying tcaNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying bmu to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying nfa to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying kux to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying stpNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying kmu to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying portft to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying xavNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying kekNT to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying crxNTpo to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying urw to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying aoj-filifita to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying sanori to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying ubu-kala to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n",
            "copying nheBl to /content/drive/Shareddrives/Partnership for Applied Biblical NLP/Data/Corpora/ebible/redistributable/projects\n"
          ]
        }
      ],
      "source": [
        "log_file = open(ebible_logs / f\"run_{date.today()}.log\", \"a\")\n",
        "log_and_print(f\"Starting converting eBible projects for extracting...\")\n",
        "\n",
        "# Create target directory if it doesn't exist already\n",
        "makedirs(ebible_redistributable, exist_ok=True)\n",
        "\n",
        "# Make dictionary of copyright free projects in eBible.\n",
        "redistributable = get_redistributable_projects()\n",
        "\n",
        "# Copy redistributable eBible projects into working directory, and add settings files\n",
        "copied = 0\n",
        "for project in ebible_projects.iterdir():\n",
        "    if project.name in redistributable:\n",
        "        copied += copy_to_working_directory(project, redistributable[project.name])\n",
        "\n",
        "log_and_print(f\"Number of eBible projects: {len([item for item in listdir(ebible_projects)])}\")\n",
        "log_and_print(f\"Number of redistributable eBible projects: {len(redistributable)}\")\n",
        "log_and_print(f\"{copied} projects copied to {ebible_redistributable}\")\n",
        "log_and_print(f\"Rewrite {rewrite}\")\n",
        "log_file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract projects"
      ],
      "metadata": {
        "id": "fYcGRtGB1eRu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoR0briHQMxU"
      },
      "source": [
        "log_file = open(ebible_logs / f\"run_{date.today()}.log\", \"a\")\n",
        "log_and_print(f\"Starting extracting eBible projects...\")\n",
        "\n",
        "# Tell the SIL NLP tools where to find the resources\n",
        "environ['SIL_NLP_DATA_PATH'] = base\n",
        "\n",
        "# Tell Python where to find our repo\n",
        "environ['PYTHONPATH'] = \"/env/python:/content/silnlp\"\n",
        "\n",
        "extracted = get_extracted_projects(ebible_extractions)\n",
        "nr_extracted = len(extracted)\n",
        "\n",
        "for project in ebible_redistributable.glob(\"*\"):\n",
        "    if not project.name in extracted or rewrite:\n",
        "        log_and_print(f\"extracting {project}\")\n",
        "        !python -m silnlp.common.extract_corpora \"{project}\"\n",
        "\n",
        "log_and_print(f\"{len(get_extracted_projects(ebible_extractions)) - nr_extracted} new eBible projects extracted\")\n",
        "log_and_print(f\"Rewrite {rewrite}\")\n",
        "log_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}